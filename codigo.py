# -*- coding: utf-8 -*-
"""analise_dados.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11au4YqUk464EYOcRQ3OQCZs6cruemAN7

# Introdução:

Neste notebook, iremos explorar os dados coletados na pesquisa anual do Datahackers de 2022. A pesquisa do Datahackers é uma fonte valiosa de informações sobre o mercado de trabalho na área de Tecnologia da Informação (TI) no Brasil, abordando uma ampla gama de tópicos relevantes para profissionais, empresas e instituições de ensino.

A importância dessa pesquisa não pode ser subestimada, pois fornece insights cruciais sobre tendências, demandas e desafios enfrentados pelos profissionais de TI no Brasil. Além disso, a pesquisa contribui significativamente para o debate sobre diversidade no setor, incluindo questões de gênero, raça e outros aspectos relacionados à inclusão.

O objetivo desta análise de dados é duplo: em primeiro lugar, buscando aprender e praticar técnicas de análise de dados utilizando Python e bibliotecas como pandas, matplotlib e seaborn. Em segundo lugar, pretendemos extrair insights importantes sobre o mercado de trabalho na área de TI, identificando padrões, tendências e correlações nos dados coletados.

Além de explorar aspectos como salários, níveis de escolaridade e tecnologias mais utilizadas, daremos um foco especial ao debate de diversidade, investigando questões de representatividade de gênero e raça no campo da tecnologia.

### Importações
"""

#Importações
from google.colab import drive
import pandas as pd

"""### Uso da biblioteca Pandas

"""

# Montando o drive
drive.mount('/content/drive')

# Lendo os dados
dados = pd.read_excel("/content/drive/MyDrive/Programaria/planilha_modulo3.xlsx")

dados

dados.head(10)

dados.tail()

dados.shape

len(dados)

dados.columns

dados.info()

dados.describe()

"""### Repetindo análise do excel"""

dados.columns

dados["GENERO"]

dados[dados["GENERO"]=="Feminino"]

dados[dados["GENERO"]!="Masculino"]

dados[dados["GENERO"].str.contains("não", na=False)]

dados[dados["IDADE"]>=30]

dados[(dados["IDADE"]>30) & (dados["GENERO"]=="Feminino")]

dados[dados["COR/RACA/ETNIA"]=="Amarela"]

dados[dados["IDADE"]<40]

dados.groupby("GENERO")["ID"].nunique()

dados.groupby("GENERO",dropna=False)["ID"].nunique()

dados["GENERO"].value_counts(dropna=False)

dados[(dados["IDADE"]>30) & (dados["GENERO"]=="Feminino")]["NIVEL"].value_counts()

pd.pivot_table(dados, values=["ID"], index=["GENERO"], columns=["GESTOR"],aggfunc="count")

"""### Estatística Básica"""

# Importar dados
import numpy as np

lista_idades = [26,30,32,22,26,35,40,20,43,31,23]

np.sum(lista_idades)

len(lista_idades)

np.sum(lista_idades)/len(lista_idades)

media = np.mean(lista_idades)
print("Média aritmética:",media)

lista_idades.sort()
lista_idades

lista_idades = [26,30,32,22,26,35,40,20,43,31,23,100]

#Colocando as idades na ordem:
lista_idades.sort()
lista_idades

mediana = np.median(lista_idades)
mediana

"""##### Voltando para a tabela"""

dados

dados["IDADE"].mean()

dados["IDADE"].median()

dados["IDADE"].mode()

dados["IDADE"].std()

dados["IDADE"].min()

dados["IDADE"].max()

dados[dados["GENERO"]=="Feminino"]["IDADE"].mean()

dados[dados["GENERO"]=="Masculino"]["IDADE"].mean()

dados[dados["GENERO"]=="Feminino"]["SALARIO"].mean()

dados[dados["GENERO"]=="Masculino"]["SALARIO"].mean()

"""### Valores faltantes"""

dados.info()

"""### Trabalhando coluna de gênero"""

dados.groupby("GENERO",dropna=False)["ID"].nunique()

dados ["GENERO"] = dados["GENERO"].fillna("Prefiro não informar")

dados.groupby("GENERO",dropna=False)["ID"].nunique()

"""### Trabalhando coluna de idade"""

dados["IDADE"].isnull().value_counts()

dados.columns

dados[dados["IDADE"].isnull()]["FAIXA IDADE"].value_counts()

media_17_21 = dados[dados["FAIXA IDADE"]=="17-21"]["IDADE"].mean()

dados.loc[(dados["FAIXA IDADE"]=="17-21") & (dados["IDADE"].isnull()),"IDADE"] = media_17_21

dados[dados["IDADE"].isnull()]["FAIXA IDADE"].value_counts()

dados[dados["FAIXA IDADE"]=="55+"]["IDADE"]

dados[dados["FAIXA IDADE"]=="55+"]["NIVEL"]

media_geral = dados["IDADE"].mean()
media_geral

dados.loc[(dados["FAIXA IDADE"]=="55+") & (dados["IDADE"].isnull()), "IDADE"] = media_geral

dados[dados["IDADE"].isnull()]["FAIXA IDADE"].value_counts()

"""### Tratando coluna salário"""

dados[dados["SALARIO"].isnull()]

dados[dados["SALARIO"].isnull()]["FAIXA SALARIAL"].value_counts()

mediana_salario = dados["SALARIO"].median()

dados.loc[dados["SALARIO"].isnull(), "SALARIO"] = mediana_salario

"""### Valores discrepantes (outliers)"""

lista_idades = [26,30,32,22,26,35,400,20,43,31,23]

media = np.mean(lista_idades)
media

desvio = np.std(lista_idades)
desvio

media + 3*desvio

media - 3*desvio

import matplotlib.pyplot as plt

plt.boxplot(lista_idades)

plt.boxplot(dados["SALARIO"])

Q1 = dados["SALARIO"].quantile(0.25)
Q1

Q3 = dados["SALARIO"].quantile(0.75)
Q3

IQR = Q3 - Q1
IQR

lim_superior = Q3 + (1.5*IQR)
lim_superior

lim_inferior = Q1 - (1.5*IQR)
lim_inferior

dados["FAIXA SALARIAL"].value_counts()

media_salario = dados["SALARIO"].mean()
media_salario

desvio_salario = dados["SALARIO"].std()
desvio_salario

limite_superior = media_salario + (3*desvio_salario)
limite_superior

dados[dados["SALARIO"]>limite_superior]["FAIXA SALARIAL"].value_counts()

media_30_40 = dados[(dados["FAIXA SALARIAL"]=="de R$ 30.001/mês a R$ 40.000/mês") & (dados["SALARIO"]<limite_superior)]["SALARIO"].mean()
media_30_40

dados.loc[(dados["FAIXA SALARIAL"]=="de R$ 30.001/mês a R$ 40.000/mês") & (dados["SALARIO"]>limite_superior), "SALARIO"] = media_30_40

dados[dados["SALARIO"]>limite_superior]["FAIXA SALARIAL"].value_counts()

acima_40 = dados[(dados["FAIXA SALARIAL"]=="Acima de R$ 40.001/mês") & (dados["SALARIO"]<limite_superior)]["SALARIO"].mean()
acima_40

dados.loc[(dados["FAIXA SALARIAL"]=="Acima de R$ 40.001/mês") & (dados["SALARIO"]>limite_superior), "SALARIO"] = acima_40

dados[dados["SALARIO"]>limite_superior]["FAIXA SALARIAL"].value_counts()

plt.boxplot(dados["SALARIO"])

"""### Distribuição Amostral e Intervalo de Confiança"""

salarios = dados["SALARIO"]

salarios

media_amostral = np.mean(salarios)
media_amostral

desvio_amostral = np.std(salarios)
desvio_amostral

nivel_confianca = 0.95

tamanho_amostra = len(salarios)
tamanho_amostra

from scipy import stats

erro_padrao = stats.sem(salarios)
erro_padrao

intervalo_confianca = stats.t.interval(nivel_confianca,tamanho_amostra-1,loc=media_amostral, scale=erro_padrao)
intervalo_confianca

"""### Feature Engineering"""

def preencher_nivel(gestor,nivel):
  if gestor==1:
    return "Pessoa Gestora"
  else:
    return nivel

dados["NOVO_NIVEL"] = dados.apply(lambda x: preencher_nivel(x["GESTOR"], x["NIVEL"]), axis=1)

dados["NOVO_NIVEL"].value_counts()

dados["NIVEL"]

dados = pd.get_dummies(dados, columns=["NIVEL"])

dados.columns

def determinar_geracao(idade):
  if 39<idade<58:
    return "Geração X"
  elif 29<idade <=39:
    return "MilLenial"
  elif 13<idade <=29:
    return "Geração Z"
  else:
    return "Outra geração"

dados["GERACAO"] = dados["IDADE"].apply(determinar_geracao)

dados["GERACAO"].value_counts()

dados2 = pd.read_excel("/content/drive/MyDrive/Programaria/Planilha_Aula_parte2.xlsx")

dados2.head()

dados = dados.merge(dados2, on="ID", how="left")

dados.columns

dados["Você pretende mudar de emprego nos próximos 6 meses?"].value_counts()

dados["EM_BUSCA"] = dados["Você pretende mudar de emprego nos próximos 6 meses?"].str.contains("em busca", case=False)

dados["EM_BUSCA"].value_counts()

dados["ABERTO_OPORTUNIDADES"] = dados["Você pretende mudar de emprego nos próximos 6 meses?"].str.contains("aberto", case=False)

dados["ABERTO_OPORTUNIDADES"].value_counts()

dados.columns

dados["COR/RACA/ETNIA"].value_counts()

def determinar_etnia(cor_raca_etnia):
  if cor_raca_etnia=="Branca":
    return "Brancas"
  elif cor_raca_etnia=="Outra" or cor_raca_etnia=="Prefiro não informar":
    return "Outras"
  else:
    return "Não branca"

dados["ETNIA"] = dados["COR/RACA/ETNIA"].apply(determinar_etnia)

dados["ETNIA"].value_counts()

"""### Correlação"""

correlacao_continua = dados["IDADE"].corr(dados["SALARIO"])
correlacao_continua

from scipy.stats import chi2_contingency

def cramer_coeficiente(coluna1, coluna2):
  tabela_cruzada = np.array(pd.crosstab(coluna1, coluna2))
  chi2 = chi2_contingency(tabela_cruzada)[0]
  soma = np.sum(tabela_cruzada)
  mini = min(tabela_cruzada.shape)-1
  cramer = np.sqrt(chi2/(soma*mini))
  return cramer

cramer_coeficiente(dados["COR/RACA/ETNIA"], dados["NIVEL DE ENSINO"])

tabela_cruzada = pd.crosstab(dados["COR/RACA/ETNIA"], dados["NIVEL DE ENSINO"])
tabela_cruzada

np.array(tabela_cruzada)

dados.to_csv("/content/drive/MyDrive/Programaria/analise_dados.csv", index=False)